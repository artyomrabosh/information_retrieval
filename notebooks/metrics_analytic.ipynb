{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a425558a",
   "metadata": {},
   "source": [
    "# Замеры метрик для текстового и гибридного поиска"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d2778c",
   "metadata": {},
   "source": [
    "Хотим проверить докидывает ли метрик векторный поиск как новый источник кандидатов, и как фича в L2 ранкере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cb238bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANALYSIS OF SEARCH RESULTS\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5l/w01pcw8913j9fpf555x1nynr0000gn/T/ipykernel_13750/3905757681.py:117: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_hybrid_text = df_hybrid_text.groupby('query_text', group_keys=False).apply(rank_by_text_score)\n",
      "/var/folders/5l/w01pcw8913j9fpf555x1nynr0000gn/T/ipykernel_13750/3905757681.py:128: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_hybrid_combined = df_hybrid_combined.groupby('query_text', group_keys=False).apply(rank_by_combined_score)\n",
      "/var/folders/5l/w01pcw8913j9fpf555x1nynr0000gn/T/ipykernel_13750/3905757681.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recall = df.groupby(group_by_col).apply(\n",
      "/var/folders/5l/w01pcw8913j9fpf555x1nynr0000gn/T/ipykernel_13750/3905757681.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recall = df.groupby(group_by_col).apply(\n",
      "/var/folders/5l/w01pcw8913j9fpf555x1nynr0000gn/T/ipykernel_13750/3905757681.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recall = df.groupby(group_by_col).apply(\n",
      "/var/folders/5l/w01pcw8913j9fpf555x1nynr0000gn/T/ipykernel_13750/3905757681.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recall = df.groupby(group_by_col).apply(\n",
      "/var/folders/5l/w01pcw8913j9fpf555x1nynr0000gn/T/ipykernel_13750/3905757681.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recall = df.groupby(group_by_col).apply(\n",
      "/var/folders/5l/w01pcw8913j9fpf555x1nynr0000gn/T/ipykernel_13750/3905757681.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recall = df.groupby(group_by_col).apply(\n",
      "/var/folders/5l/w01pcw8913j9fpf555x1nynr0000gn/T/ipykernel_13750/3905757681.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recall = df.groupby(group_by_col).apply(\n",
      "/var/folders/5l/w01pcw8913j9fpf555x1nynr0000gn/T/ipykernel_13750/3905757681.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recall = df.groupby(group_by_col).apply(\n",
      "/var/folders/5l/w01pcw8913j9fpf555x1nynr0000gn/T/ipykernel_13750/3905757681.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recall = df.groupby(group_by_col).apply(\n",
      "/var/folders/5l/w01pcw8913j9fpf555x1nynr0000gn/T/ipykernel_13750/3905757681.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recall = df.groupby(group_by_col).apply(\n",
      "/var/folders/5l/w01pcw8913j9fpf555x1nynr0000gn/T/ipykernel_13750/3905757681.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recall = df.groupby(group_by_col).apply(\n",
      "/var/folders/5l/w01pcw8913j9fpf555x1nynr0000gn/T/ipykernel_13750/3905757681.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recall = df.groupby(group_by_col).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "COMPARISON OF HYBRID SEARCH RANKING METHODS\n",
      "====================================================================================================\n",
      "\n",
      "                Method MRR@10 Precision@10 nDCG@10  AP@10 Recall@1 Recall@5 Recall@10 Recall@20 Avg Rank  Queries\n",
      "                  text 0.4220       0.0222  0.5558 0.0900    5.11%   13.61%    21.32%    30.23%     16.0      999\n",
      "                hybrid 0.4807       0.0494  0.6016 0.2377   14.91%   34.83%    49.45%    63.86%     16.3      999\n",
      "hybrid_with_l2_feature 0.8423       0.0906  0.8809 0.7631   68.17%   86.59%    90.59%    92.89%      2.8      999\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def calculate_metrics_for_ranking(df: pd.DataFrame, rank_col: str = 'rank', \n",
    "                                  group_by_col: str = 'query_text') -> Dict:\n",
    "    \"\"\"Расчет метрик для заданного способа ранжирования\"\"\"\n",
    "    \n",
    "    # Recall@k\n",
    "    recall_at_k = {}\n",
    "    for k in [1, 5, 10, 20]:\n",
    "        recall = df.groupby(group_by_col).apply(\n",
    "            lambda x: ((x[rank_col] <= k) & (x['relevant'] == 1)).any()\n",
    "        ).mean()\n",
    "        recall_at_k[k] = recall\n",
    "    \n",
    "    # MRR@10\n",
    "    first_relevant_ranks = df[df['relevant'] == 1].groupby(group_by_col)[rank_col].min()\n",
    "    first_relevant_ranks = first_relevant_ranks[first_relevant_ranks <= 10]\n",
    "    reciprocal_ranks = 1.0 / first_relevant_ranks\n",
    "    mrr = reciprocal_ranks.mean() if len(reciprocal_ranks) > 0 else 0\n",
    "    \n",
    "    # Precision@10\n",
    "    df_top10 = df[df[rank_col] <= 10]\n",
    "    precision_at_10 = df_top10.groupby(group_by_col)['relevant'].mean().mean()\n",
    "    \n",
    "    # nDCG@10\n",
    "    ndcg_at_10 = calculate_ndcg(df, rank_col, group_by_col, k=10)\n",
    "    \n",
    "    # Average Precision@10\n",
    "    ap_at_10 = calculate_average_precision(df, rank_col, group_by_col, k=10)\n",
    "    \n",
    "    return {\n",
    "        'recall': recall_at_k,\n",
    "        'mrr@10': mrr,\n",
    "        'precision@10': precision_at_10,\n",
    "        'ndcg@10': ndcg_at_10,\n",
    "        'ap@10': ap_at_10,\n",
    "        'queries_processed': df[group_by_col].nunique(),\n",
    "        'avg_rank_relevant': df[df['relevant'] == 1][rank_col].mean()\n",
    "    }\n",
    "\n",
    "def calculate_ndcg(df: pd.DataFrame, rank_col: str, group_by_col: str, k: int = 10) -> float:\n",
    "    \"\"\"Расчет nDCG@k\"\"\"\n",
    "    ndcg_scores = []\n",
    "    \n",
    "    for query in df[group_by_col].unique():\n",
    "        query_results = df[df[group_by_col] == query]\n",
    "        query_results = query_results.sort_values(rank_col).head(k)\n",
    "        \n",
    "        # Получаем релевантности и ранги\n",
    "        y_true = query_results['relevant'].values\n",
    "        if len(y_true) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Идеальный порядок (отсортированный по релевантности)\n",
    "        ideal_order = np.sort(y_true)[::-1]\n",
    "        \n",
    "        # Расчет DCG\n",
    "        dcg = np.sum(y_true / np.log2(np.arange(2, len(y_true) + 2)))\n",
    "        \n",
    "        # Расчет идеального DCG\n",
    "        idcg = np.sum(ideal_order / np.log2(np.arange(2, len(ideal_order) + 2)))\n",
    "        \n",
    "        if idcg > 0:\n",
    "            ndcg = dcg / idcg\n",
    "            ndcg_scores.append(ndcg)\n",
    "    \n",
    "    return np.mean(ndcg_scores) if ndcg_scores else 0\n",
    "\n",
    "def calculate_average_precision(df: pd.DataFrame, rank_col: str, \n",
    "                               group_by_col: str, k: int = 10) -> float:\n",
    "    \"\"\"Расчет Average Precision@k\"\"\"\n",
    "    ap_scores = []\n",
    "    \n",
    "    for query in df[group_by_col].unique():\n",
    "        query_results = df[df[group_by_col] == query]\n",
    "        query_results = query_results.sort_values(rank_col).head(k)\n",
    "        \n",
    "        relevant_docs = query_results[query_results['relevant'] == 1]\n",
    "        if len(relevant_docs) == 0:\n",
    "            ap_scores.append(0)\n",
    "            continue\n",
    "        \n",
    "        precisions = []\n",
    "        for idx, (_, row) in enumerate(relevant_docs.iterrows(), 1):\n",
    "            # Precision на текущем ранге\n",
    "            precision_at_r = idx / row[rank_col]\n",
    "            precisions.append(precision_at_r)\n",
    "        \n",
    "        ap = np.mean(precisions) if precisions else 0\n",
    "        ap_scores.append(ap)\n",
    "    \n",
    "    return np.mean(ap_scores) if ap_scores else 0\n",
    "\n",
    "def compare_hybrid_rankings(df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"Сравнение разных способов ранжирования в гибридном поиске\"\"\"\n",
    "    \n",
    "    # Фильтруем только гибридный поиск\n",
    "    df_hybrid = df[df['search_type'] == 'hybrid'].copy()\n",
    "    df_text = df[df['search_type'] == 'text'].copy()\n",
    "    \n",
    "    # Создаем два разных ранжирования для гибридного поиска\n",
    "    \n",
    "    # 1. Оригинальное ранжирование (по score)\n",
    "    df_hybrid_original = df_hybrid.copy()\n",
    "    \n",
    "    # 2. Ранжирование по score_text_only\n",
    "    df_hybrid_text = df_hybrid.copy()\n",
    "    \n",
    "    # Для каждого запроса пересчитываем ранги по score_text_only\n",
    "    def rank_by_text_score(group):\n",
    "        group = group.sort_values('score_text_only', ascending=False)\n",
    "        group['rank_text_only'] = range(1, len(group) + 1)\n",
    "        return group\n",
    "    \n",
    "    df_hybrid_text = df_hybrid_text.groupby('query_text', group_keys=False).apply(rank_by_text_score)\n",
    "    \n",
    "    # 3. Ранжирование по комбинации score и score_text_only (например, среднее)\n",
    "    df_hybrid_combined = df_hybrid.copy()\n",
    "    df_hybrid_combined['combined_score'] = 0.7 * df_hybrid_combined['score'] + 0.3 * df_hybrid_combined['score_text_only']\n",
    "    \n",
    "    def rank_by_combined_score(group):\n",
    "        group = group.sort_values('combined_score', ascending=False)\n",
    "        group['rank_combined'] = range(1, len(group) + 1)\n",
    "        return group\n",
    "    \n",
    "    df_hybrid_combined = df_hybrid_combined.groupby('query_text', group_keys=False).apply(rank_by_combined_score)\n",
    "    \n",
    "    # Считаем метрики для каждого способа\n",
    "    metrics_original = calculate_metrics_for_ranking(df_hybrid_original, 'rank', 'query_text')\n",
    "    metrics_text_only = calculate_metrics_for_ranking(df_hybrid_text, 'rank_text_only', 'query_text')\n",
    "    metrics_text = calculate_metrics_for_ranking(df_text, 'rank', 'query_text')\n",
    "    \n",
    "    return {\n",
    "        'text': metrics_text,\n",
    "        'hybrid': metrics_text_only,\n",
    "        'hybrid_with_l2_feature': metrics_original,\n",
    "    }\n",
    "\n",
    "\n",
    "def print_metrics_comparison(metrics_dict: Dict):\n",
    "    \"\"\"Красивый вывод сравнения метрик\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"COMPARISON OF HYBRID SEARCH RANKING METHODS\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Создаем DataFrame для удобного отображения\n",
    "    comparison_data = []\n",
    "    \n",
    "    for method_name, metrics in metrics_dict.items():\n",
    "        comparison_data.append({\n",
    "            'Method': method_name,\n",
    "            'MRR@10': f\"{metrics['mrr@10']:.4f}\",\n",
    "            'Precision@10': f\"{metrics['precision@10']:.4f}\",\n",
    "            'nDCG@10': f\"{metrics['ndcg@10']:.4f}\",\n",
    "            'AP@10': f\"{metrics['ap@10']:.4f}\",\n",
    "            'Recall@1': f\"{metrics['recall'][1]:.2%}\",\n",
    "            'Recall@5': f\"{metrics['recall'][5]:.2%}\",\n",
    "            'Recall@10': f\"{metrics['recall'][10]:.2%}\",\n",
    "            'Recall@20': f\"{metrics['recall'][20]:.2%}\",\n",
    "            'Avg Rank': f\"{metrics['avg_rank_relevant']:.1f}\",\n",
    "            'Queries': metrics['queries_processed']\n",
    "        })\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Выводим таблицу\n",
    "    print(\"\\n\" + df_comparison.to_string(index=False))\n",
    "    \n",
    "    # Рассчитываем улучшения\n",
    "    if 'hybrid_original' in metrics_dict and 'hybrid_text_only' in metrics_dict:\n",
    "        orig = metrics_dict['hybrid_original']\n",
    "        text = metrics_dict['hybrid_text_only']\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        print(\"IMPROVEMENT OF TEXT-ONLY RANKING OVER ORIGINAL HYBRID:\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        improvements = {\n",
    "            'MRR@10': (text['mrr@10'] - orig['mrr@10']) / orig['mrr@10'] * 100 if orig['mrr@10'] > 0 else 0,\n",
    "            'Precision@10': (text['precision@10'] - orig['precision@10']) / orig['precision@10'] * 100 if orig['precision@10'] > 0 else 0,\n",
    "            'Recall@10': (text['recall'][10] - orig['recall'][10]) / orig['recall'][10] * 100 if orig['recall'][10] > 0 else 0,\n",
    "        }\n",
    "        \n",
    "        for metric, improvement in improvements.items():\n",
    "            direction = \"↑\" if improvement > 0 else \"↓\"\n",
    "            print(f\"  {metric}: {direction} {improvement:+.1f}%\")\n",
    "        \n",
    "        best_method = max(metrics_dict.items(), \n",
    "                         key=lambda x: x[1]['mrr@10'] * 0.4 + \n",
    "                                      x[1]['precision@10'] * 0.3 + \n",
    "                                      x[1]['recall'][10] * 0.3)\n",
    "        \n",
    "        print(f\"\\n★ Best method by weighted score: {best_method[0]} \"\n",
    "              f\"(MRR: {best_method[1]['mrr@10']:.4f}, P@10: {best_method[1]['precision@10']:.4f})\")\n",
    "\n",
    "df = pd.read_parquet(\"../search_results.parquet\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANALYSIS OF SEARCH RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "hybrid_comparison = compare_hybrid_rankings(df)\n",
    "print_metrics_comparison(hybrid_comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3bb43c",
   "metadata": {},
   "source": [
    "Добавление векторного источника кандидатов докидывает метрик, но сильный прирост видно именно после добавления фичи в ранжирующую модель"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
