{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9470e407",
   "metadata": {},
   "source": [
    "# Load documents and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b25836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arabosh/information_retrieval/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/arabosh/information_retrieval/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.76568747e-02  6.34958595e-02  4.87131178e-02  7.93049559e-02\n",
      "   3.74480337e-02  2.65277526e-03  3.93749252e-02 -7.09843542e-03\n",
      "   5.93614802e-02  3.15370075e-02  6.00980483e-02 -5.29051833e-02\n",
      "   4.06067744e-02 -2.59308163e-02  2.98427958e-02  1.12689717e-03\n",
      "   7.35149533e-02 -5.03819808e-02 -1.22386612e-01  2.37028506e-02\n",
      "   2.97265295e-02  4.24768887e-02  2.56337821e-02  1.99517887e-03\n",
      "  -5.69191203e-02 -2.71598324e-02 -3.29035446e-02  6.60248548e-02\n",
      "   1.19007103e-01 -4.58791442e-02 -7.26214871e-02 -3.25839780e-02\n",
      "   5.23413755e-02  4.50552665e-02  8.25300161e-03  3.67023759e-02\n",
      "  -1.39415069e-02  6.53919056e-02 -2.64272504e-02  2.06405064e-04\n",
      "  -1.36643583e-02 -3.62809747e-02 -1.95043441e-02 -2.89738420e-02\n",
      "   3.94270532e-02 -8.84090886e-02  2.62426329e-03  1.36713851e-02\n",
      "   4.83063050e-02 -3.11565753e-02 -1.17329188e-01 -5.11689894e-02\n",
      "  -8.85287374e-02 -2.18962021e-02  1.42986281e-02  4.44167629e-02\n",
      "  -1.34814661e-02  7.43392557e-02  2.66382862e-02 -1.98762454e-02\n",
      "   1.79190896e-02 -1.06052700e-02 -9.04263109e-02  2.13269275e-02\n",
      "   1.41204819e-01 -6.47172704e-03 -1.40387495e-03 -1.53610045e-02\n",
      "  -8.73571783e-02  7.22174197e-02  2.01402754e-02  4.25587520e-02\n",
      "  -3.49014029e-02  3.19654151e-04 -8.02970603e-02 -3.27472202e-02\n",
      "   2.85268463e-02 -5.13658039e-02  1.09389216e-01  8.19328129e-02\n",
      "  -9.84039679e-02 -9.34095159e-02 -1.51292328e-02  4.51248027e-02\n",
      "   4.94171754e-02 -2.51867957e-02  1.57077312e-02 -1.29290745e-01\n",
      "   5.31896250e-03  4.02345462e-03 -2.34572515e-02 -6.72983155e-02\n",
      "   2.92280857e-02 -2.60845292e-02  1.30625125e-02 -3.11663412e-02\n",
      "  -4.82713804e-02 -5.58859780e-02 -3.87505516e-02  1.20010801e-01\n",
      "  -1.03924572e-02  4.89704721e-02  5.53537123e-02  4.49359231e-02\n",
      "  -4.00965754e-03 -1.02959722e-01 -2.92968899e-02 -5.83402030e-02\n",
      "   2.70472337e-02 -2.20169481e-02 -7.22241625e-02 -4.13869284e-02\n",
      "  -1.93298291e-02  2.73330277e-03  2.76933308e-04 -9.67587903e-02\n",
      "  -1.00574754e-01 -1.41922981e-02 -8.07891265e-02  4.53925580e-02\n",
      "   2.45040692e-02  5.97613864e-02 -7.38185421e-02  1.19843744e-02\n",
      "  -6.63403198e-02 -7.69044980e-02  3.85157354e-02 -5.59362036e-33\n",
      "   2.80013476e-02 -5.60784601e-02 -4.86601964e-02  2.15569939e-02\n",
      "   6.01980612e-02 -4.81402948e-02 -3.50246802e-02  1.93314161e-02\n",
      "  -1.75151862e-02 -3.89210358e-02 -3.81064019e-03 -1.70287527e-02\n",
      "   2.82099545e-02  1.28290448e-02  4.71601486e-02  6.21029846e-02\n",
      "  -6.43588528e-02  1.29285634e-01 -1.31231491e-02  5.23069501e-02\n",
      "  -3.73680927e-02  2.89094560e-02 -1.68980937e-02 -2.37330459e-02\n",
      "  -3.33491974e-02 -5.16762957e-02  1.55356703e-02  2.08802931e-02\n",
      "  -1.25371125e-02  4.59579043e-02  3.72720398e-02  2.80566942e-02\n",
      "  -5.90005554e-02 -1.16988560e-02  4.92182150e-02  4.70328555e-02\n",
      "   7.35487416e-02 -3.70529853e-02  3.98456817e-03  1.06411912e-02\n",
      "  -1.61577569e-04 -5.27166352e-02  2.75927465e-02 -3.92921679e-02\n",
      "   8.44717771e-02  4.86860871e-02 -4.85879276e-03  1.79948378e-02\n",
      "  -4.28569838e-02  1.23375477e-02  6.39955560e-03  4.04822864e-02\n",
      "   1.48887401e-02 -1.53941503e-02  7.62947649e-02  2.37043705e-02\n",
      "   4.45237383e-02  5.08195162e-02 -2.31254240e-03 -1.88737269e-02\n",
      "  -1.23335812e-02  4.66002785e-02 -5.63438050e-02  6.29926845e-02\n",
      "  -3.15534957e-02  3.24912556e-02  2.34673116e-02 -6.55437633e-02\n",
      "   2.01709159e-02  2.57082637e-02 -1.23868277e-02 -8.36497918e-03\n",
      "  -6.64377958e-02  9.43073928e-02 -3.57092544e-02 -3.42483260e-02\n",
      "  -6.66350406e-03 -8.01526383e-03 -3.09711229e-02  4.33012247e-02\n",
      "  -8.21393728e-03 -1.50795028e-01  3.07692476e-02  4.00718674e-02\n",
      "  -3.79294045e-02  1.93210354e-03  4.00530323e-02 -8.77074674e-02\n",
      "  -3.68491821e-02  8.57952796e-03 -3.19251604e-02 -1.25258071e-02\n",
      "   7.35539198e-02  1.34740095e-03  2.05919072e-02  2.71097981e-33\n",
      "  -5.18576950e-02  5.78360669e-02 -9.18985233e-02  3.94422002e-02\n",
      "   1.05576538e-01 -1.96912158e-02  6.18402325e-02 -7.63464421e-02\n",
      "   2.40880493e-02  9.40049365e-02 -1.16535500e-01  3.71198468e-02\n",
      "   5.22424914e-02 -3.95852095e-03  5.72214499e-02  5.32855373e-03\n",
      "   1.24016762e-01  1.39022395e-02 -1.10249817e-02  3.56053337e-02\n",
      "  -3.30754556e-02  8.16574097e-02 -1.52003784e-02  6.05584830e-02\n",
      "  -6.01397380e-02  3.26102600e-02 -3.48296762e-02 -1.69881862e-02\n",
      "  -9.74907726e-02 -2.71483455e-02  1.74705940e-03 -7.68982098e-02\n",
      "  -4.31858376e-02 -1.89985689e-02 -2.91660931e-02  5.77488318e-02\n",
      "   2.41821520e-02 -1.16901910e-02 -6.21434785e-02  2.84351576e-02\n",
      "  -2.37508197e-04 -2.51783449e-02  4.39634407e-03  8.12840015e-02\n",
      "   3.64184566e-02 -6.04006313e-02 -3.65517735e-02 -7.93748051e-02\n",
      "  -5.08531556e-03  6.69699460e-02 -1.17784351e-01  3.23743969e-02\n",
      "  -4.71252389e-02 -1.34459864e-02 -9.48445573e-02  8.24948121e-03\n",
      "  -1.06748892e-02 -6.81882203e-02  1.11816206e-03  2.48019788e-02\n",
      "  -6.35889694e-02  2.84492522e-02 -2.61303373e-02  8.58111456e-02\n",
      "   1.14682309e-01 -5.35345748e-02 -5.63588440e-02  4.26008701e-02\n",
      "   1.09453965e-02  2.09578406e-02  1.00131184e-01  3.26051638e-02\n",
      "  -1.84208781e-01 -3.93208265e-02 -6.91454709e-02 -6.38105273e-02\n",
      "  -6.56385571e-02 -6.41251728e-03 -4.79612313e-02 -7.68133551e-02\n",
      "   2.95384377e-02 -2.29948480e-02  4.17037047e-02 -2.50047371e-02\n",
      "  -4.54506604e-03 -4.17136401e-02 -1.32289249e-02 -6.38357922e-02\n",
      "  -2.46473379e-03 -1.37337632e-02  1.68976337e-02 -6.30398393e-02\n",
      "   8.98881108e-02  4.18170877e-02 -1.85687263e-02 -1.80442150e-08\n",
      "  -1.67998187e-02 -3.21577750e-02  6.30383939e-02 -4.13092338e-02\n",
      "   4.44819108e-02  2.02468899e-03  6.29592836e-02 -5.17373672e-03\n",
      "  -1.00444043e-02 -3.05640977e-02  3.52672413e-02  5.58581464e-02\n",
      "  -4.67124805e-02  3.45102735e-02  3.29577364e-02  4.30114307e-02\n",
      "   2.94361431e-02 -3.03163994e-02 -1.71107519e-02  7.37485141e-02\n",
      "  -5.47909737e-02  2.77515389e-02  6.20167190e-03  1.58800781e-02\n",
      "   3.42978723e-02 -5.15753916e-03  2.35079303e-02  7.53135607e-02\n",
      "   1.92843340e-02  3.36196758e-02  5.09103462e-02  1.52497053e-01\n",
      "   1.64207797e-02  2.70528588e-02  3.75162773e-02  2.18553599e-02\n",
      "   5.66333830e-02 -3.95747572e-02  7.12313652e-02 -5.41377030e-02\n",
      "   1.03774422e-03  2.11852901e-02 -3.56308818e-02  1.09017022e-01\n",
      "   2.76528974e-03  3.13997231e-02  1.38424640e-03 -3.45738679e-02\n",
      "  -4.59277891e-02  2.88083702e-02  7.16907298e-03  4.84684929e-02\n",
      "   2.61018276e-02 -9.44076478e-03  2.82169189e-02  3.48723754e-02\n",
      "   3.69098224e-02 -8.58947914e-03 -3.53205875e-02 -2.47856844e-02\n",
      "  -1.91921368e-02  3.80708165e-02  5.99654056e-02 -4.22286727e-02]\n",
      " [ 8.64385739e-02  1.02762625e-01  5.39454306e-03  2.04443326e-03\n",
      "  -9.96337738e-03  2.53855083e-02  4.92875762e-02 -3.06265764e-02\n",
      "   6.87254816e-02  1.01365754e-02  7.75397718e-02 -9.00807008e-02\n",
      "   6.10614894e-03 -5.69898598e-02  1.41714867e-02  2.80491374e-02\n",
      "  -8.68464559e-02  7.64399171e-02 -1.03491269e-01 -6.77437931e-02\n",
      "   6.99946955e-02  8.44250768e-02 -7.24917371e-03  1.04770493e-02\n",
      "   1.34020830e-02  6.77576736e-02 -9.42086279e-02 -3.71690132e-02\n",
      "   5.22617623e-02 -3.10853403e-02 -9.63406861e-02  1.57716945e-02\n",
      "   2.57866699e-02  7.85245001e-02  7.89949223e-02  1.91516671e-02\n",
      "   1.64356716e-02  3.10082943e-03  3.81311364e-02  2.37090699e-02\n",
      "   1.05389468e-02 -4.40645032e-02  4.41738293e-02 -2.58727688e-02\n",
      "   6.15378767e-02 -4.05427851e-02 -8.64140242e-02  3.19722705e-02\n",
      "  -8.90718249e-04 -2.44437046e-02 -9.19721350e-02  2.33939476e-02\n",
      "  -8.30293596e-02  4.41510603e-02 -2.49692909e-02  6.23020232e-02\n",
      "  -1.30345754e-03  7.51395449e-02  2.46385057e-02 -6.47244230e-02\n",
      "  -1.17727794e-01  3.83391939e-02 -9.11767483e-02  6.35446385e-02\n",
      "   7.62739554e-02 -8.80241171e-02  9.54559818e-03 -4.69717495e-02\n",
      "  -8.41740668e-02  3.88823636e-02 -1.14393599e-01  6.28858525e-03\n",
      "  -3.49361561e-02  2.39750668e-02 -3.31317075e-02 -1.57244354e-02\n",
      "  -3.78955267e-02 -8.81247688e-03  7.06118867e-02  3.28066312e-02\n",
      "   2.03674170e-03 -1.12278953e-01  6.79720333e-03  1.22765144e-02\n",
      "   3.35303359e-02 -1.36200562e-02 -2.25490201e-02 -2.25228816e-02\n",
      "  -2.03194357e-02  5.04297577e-02 -7.48652816e-02 -8.22822377e-02\n",
      "   7.65962526e-02  4.93392199e-02 -3.75553407e-02  1.44634554e-02\n",
      "  -5.72457798e-02 -1.79954264e-02  1.09697945e-01  1.19462810e-01\n",
      "   8.09219782e-04  6.17057383e-02  3.26322839e-02 -1.30780071e-01\n",
      "  -1.48636609e-01 -6.16232641e-02  4.33886014e-02  2.67129093e-02\n",
      "   1.39785875e-02 -3.94002721e-02 -2.52711568e-02  3.87741043e-03\n",
      "   3.58664803e-02 -6.15420155e-02  3.76660638e-02  2.67564878e-02\n",
      "  -3.82659286e-02 -3.54793519e-02 -2.39227284e-02  8.67977366e-02\n",
      "  -1.84063166e-02  7.71039352e-02  1.39866001e-03  7.00382888e-02\n",
      "  -4.77877855e-02 -7.89819956e-02  5.10814115e-02 -2.99868370e-33\n",
      "  -3.91646028e-02 -2.56207981e-03  1.65210217e-02  9.48942732e-03\n",
      "  -5.66219501e-02  6.57782704e-02 -4.77002785e-02  1.11661777e-02\n",
      "  -5.73558547e-02 -9.16258246e-03 -2.17521135e-02 -5.59531562e-02\n",
      "  -1.11422855e-02  9.32793543e-02  1.66765023e-02 -1.36723835e-02\n",
      "   4.34388295e-02  1.87245081e-03  7.29950843e-03  5.16332164e-02\n",
      "   4.80608642e-02  1.35341495e-01 -1.71739161e-02 -1.29698254e-02\n",
      "  -7.50109553e-02  2.61107683e-02  2.69802175e-02  7.83026451e-04\n",
      "  -4.87270094e-02  1.17842732e-02 -4.59580310e-02 -4.83213812e-02\n",
      "  -1.95671134e-02  1.93889271e-02  1.98807288e-02  1.67432074e-02\n",
      "   9.87800956e-02 -2.74088010e-02  2.34809052e-02  3.70230456e-03\n",
      "  -6.14514835e-02 -1.21231459e-03 -9.50474571e-03  9.25155822e-03\n",
      "   2.38443911e-02  8.61232132e-02  2.26789974e-02  5.45123534e-04\n",
      "   3.47130001e-02  6.25460362e-03 -6.92774402e-03  3.92400548e-02\n",
      "   1.15674678e-02  3.26279700e-02  6.22155890e-02  2.76114698e-02\n",
      "   1.86883658e-02  3.55805457e-02  4.11795899e-02  1.54781919e-02\n",
      "   4.22691330e-02  3.82248461e-02  1.00313434e-02 -2.83246059e-02\n",
      "   4.47052531e-02 -4.10458855e-02 -4.50550579e-03 -5.44734448e-02\n",
      "   2.62321215e-02  1.79862157e-02 -1.23118803e-01 -4.66952212e-02\n",
      "  -1.35913305e-02  6.46710172e-02  3.57351010e-03 -1.22234048e-02\n",
      "  -1.79382116e-02 -2.55502257e-02  2.37224214e-02  4.08667419e-03\n",
      "  -6.51475787e-02  4.43651788e-02  4.68596108e-02 -3.25174890e-02\n",
      "   4.02269745e-03 -3.97602795e-03  1.11939488e-02 -9.95597839e-02\n",
      "   3.33168209e-02  8.01060796e-02  9.42692235e-02 -6.38293996e-02\n",
      "   3.23151685e-02 -5.13553508e-02 -7.49874022e-03  5.30048357e-34\n",
      "  -4.13194560e-02  9.49646682e-02 -1.06401436e-01  4.96590771e-02\n",
      "  -3.41913775e-02 -3.16745825e-02 -1.71556231e-02  1.70103996e-03\n",
      "   5.79758100e-02 -1.21779332e-03 -1.68536305e-02 -5.16912565e-02\n",
      "   5.52998669e-02 -3.42647582e-02  3.08179092e-02 -3.10481377e-02\n",
      "   9.27532613e-02  3.72663587e-02 -2.37397943e-02  4.45893556e-02\n",
      "   1.46153355e-02  1.16239332e-01 -5.00112548e-02  3.88716161e-02\n",
      "   4.24750522e-03  2.56976150e-02  3.27243470e-02  4.29907925e-02\n",
      "  -1.36144813e-02  2.56122351e-02  1.06262323e-02 -8.46864283e-02\n",
      "  -9.52982083e-02  1.08399846e-01 -7.51600415e-02 -1.37773557e-02\n",
      "   6.37338012e-02 -4.49669361e-03 -3.25321332e-02  6.23614043e-02\n",
      "   3.48053016e-02 -3.54922265e-02 -2.00222302e-02  3.66608091e-02\n",
      "  -2.48837247e-02  1.01819132e-02 -7.01233298e-02 -4.31951024e-02\n",
      "   2.95332558e-02 -2.94990838e-04 -3.45386490e-02  1.46675874e-02\n",
      "  -9.83970016e-02 -4.70488295e-02 -8.85493215e-03 -8.89914185e-02\n",
      "   3.50996070e-02 -1.29602015e-01 -4.98866029e-02 -6.12047426e-02\n",
      "  -5.97797073e-02  9.46318358e-03  4.91217896e-02 -7.75026679e-02\n",
      "   8.09726715e-02 -4.79257628e-02  2.34379363e-03  7.57031068e-02\n",
      "  -2.40175854e-02 -1.52546111e-02  4.86738794e-02 -3.85968946e-02\n",
      "  -7.04831481e-02 -1.20348064e-02 -3.88790481e-02 -7.76017085e-02\n",
      "  -1.07243471e-02  1.04187764e-02 -2.13753786e-02 -9.17386636e-02\n",
      "  -1.11344717e-02 -2.96066087e-02  2.46458054e-02  4.65711718e-03\n",
      "  -1.63449924e-02 -3.95219512e-02  7.73373619e-02 -2.84732971e-02\n",
      "  -3.69940721e-03  8.27665329e-02 -1.10409139e-02  3.13983820e-02\n",
      "   5.35094216e-02  5.75145446e-02 -3.17622125e-02 -1.52911266e-08\n",
      "  -7.99661204e-02 -4.76797111e-02 -8.59788507e-02  5.69616221e-02\n",
      "  -4.08866480e-02  2.23832447e-02 -4.64447029e-03 -3.80131193e-02\n",
      "  -3.10670901e-02 -1.07278358e-02  1.97698604e-02  7.77003635e-03\n",
      "  -6.09473744e-03 -3.86376269e-02  2.80271992e-02  6.78138584e-02\n",
      "  -2.35351119e-02  3.21747810e-02  8.02538078e-03 -2.39106975e-02\n",
      "  -1.21999951e-03  3.14599350e-02 -5.24923988e-02 -8.06812383e-03\n",
      "   3.14771105e-03  5.11496738e-02 -4.44104522e-02  6.36013374e-02\n",
      "   3.85083966e-02  3.30432728e-02 -4.18728404e-03  4.95592877e-02\n",
      "  -5.69605008e-02 -6.49711443e-03 -2.49793231e-02 -1.60866939e-02\n",
      "   6.62288815e-02 -2.06310656e-02  1.08045764e-01  1.68547146e-02\n",
      "   1.43813230e-02 -1.32126994e-02 -1.29387408e-01  6.95216581e-02\n",
      "  -5.55773005e-02 -6.75413311e-02 -5.45818452e-03 -6.13592798e-03\n",
      "   3.90841030e-02 -6.28779680e-02  3.74063551e-02 -1.16571002e-02\n",
      "   1.29150227e-02 -5.52495159e-02  5.16075715e-02 -4.30838019e-03\n",
      "   5.80247380e-02  1.86945070e-02  2.27810666e-02  3.21665853e-02\n",
      "   5.37978932e-02  7.02849403e-02  7.49312192e-02 -8.41775164e-02]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_documents = pd.read_csv(\"../datasets/documents_train.csv\", index_col=0)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e1fdf6",
   "metadata": {},
   "source": [
    "# Simple embedding of entire document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c26e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 115.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c156bd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35885/35885 [09:36<00:00, 62.22it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "train_documents[\"embedding\"] = train_documents.body.progress_apply(lambda x: model.encode(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10cd9eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents.to_csv(\"../datasets/documents_train_embedded.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85c5099",
   "metadata": {},
   "source": [
    "# Cut docs to chunks and build FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10708d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import faiss\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "\n",
    "\n",
    "class VectorSearchPreprocessor:\n",
    "    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Инициализация модели и токенизатора\n",
    "        \"\"\"\n",
    "        print(f\"Загрузка модели {model_name}...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.max_tokens = 256\n",
    "        self.passage_tokens = 128\n",
    "        self.overlap_tokens = 32\n",
    "        \n",
    "    def split_into_passages(self, text: str, doc_id: str, title: str = \"\") -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Разбивает текст на перекрывающиеся пассажи\n",
    "        \"\"\"\n",
    "        tokens = self.tokenizer.encode(text, add_special_tokens=False)\n",
    "        \n",
    "        passages = []\n",
    "        start = 0\n",
    "        \n",
    "        title_tokens = []\n",
    "        if title:\n",
    "            title_tokens = self.tokenizer.encode(title, add_special_tokens=False)\n",
    "        \n",
    "        while start < len(tokens):\n",
    "            end = min(start + self.passage_tokens, len(tokens))\n",
    "            \n",
    "            if start == 0 and title_tokens:\n",
    "                available_tokens = self.passage_tokens - len(title_tokens) - 2  # -2 для [CLS] и [SEP]\n",
    "                passage_tokens = title_tokens + tokens[start:start + available_tokens]\n",
    "                start += available_tokens\n",
    "            else:\n",
    "                passage_tokens = tokens[start:end]\n",
    "                start = end - self.overlap_tokens  # перекрытие\n",
    "            \n",
    "            passage_text = self.tokenizer.decode(passage_tokens)\n",
    "            char_start = self._find_char_position(text, tokens, start if start > 0 else 0)\n",
    "            char_end = self._find_char_position(text, tokens, end)\n",
    "            \n",
    "            passages.append({\n",
    "                'passage_tokens': passage_tokens,\n",
    "                'passage_text': passage_text,\n",
    "                'char_start': char_start,\n",
    "                'char_end': char_end,\n",
    "                'doc_id': doc_id,\n",
    "                'title': title,\n",
    "                'token_start': start if start > 0 else 0,\n",
    "                'token_end': end\n",
    "            })\n",
    "            \n",
    "            if end == len(tokens):\n",
    "                break\n",
    "        \n",
    "        return passages\n",
    "    \n",
    "    def _find_char_position(self, text: str, tokens: List[int], token_idx: int) -> int:\n",
    "        \"\"\"\n",
    "        Находит позицию символа по индексу токена\n",
    "        \"\"\"\n",
    "        if token_idx >= len(tokens):\n",
    "            return len(text)\n",
    "        \n",
    "        decoded = self.tokenizer.decode(tokens[:token_idx])\n",
    "        return len(decoded)\n",
    "    \n",
    "    def generate_embeddings(self, passages: List[Dict], batch_size: int = 32) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Генерирует эмбеддинги для пассажей\n",
    "        Возвращает нормализованные векторы для косинусного сходства\n",
    "        \"\"\"\n",
    "        all_embeddings = []\n",
    "        \n",
    "        print(f\"Генерация эмбеддингов для {len(passages)} пассажей...\")\n",
    "        \n",
    "        for i in tqdm(range(0, len(passages), batch_size)):\n",
    "            batch = passages[i:i + batch_size]\n",
    "            batch_texts = [p['passage_text'] for p in batch]\n",
    "            \n",
    "            inputs = self.tokenizer(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=self.passage_tokens + 10,  # небольшой запас\n",
    "                return_tensors='pt'\n",
    "            ).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "                attention_mask = inputs['attention_mask']\n",
    "                token_embeddings = outputs.last_hidden_state\n",
    "                \n",
    "                input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "                sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "                sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "                embeddings = sum_embeddings / sum_mask\n",
    "                \n",
    "                embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "                \n",
    "                all_embeddings.append(embeddings.cpu().numpy())\n",
    "        \n",
    "        return np.vstack(all_embeddings)\n",
    "    \n",
    "    def process_dataframe(self, df: pd.DataFrame, text_column: str = 'body', \n",
    "                         title_column: str = 'title', id_column: str = 'doc_id') -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Обрабатывает весь DataFrame\n",
    "        Возвращает DataFrame с пассажами и матрицу эмбеддингов\n",
    "        \"\"\"\n",
    "        all_passages = []\n",
    "        \n",
    "        print(\"Разбиение документов на пассажи...\")\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            doc_id = row[id_column]\n",
    "            text = row[text_column]\n",
    "            title = str(row[title_column])\n",
    "            \n",
    "            passages = self.split_into_passages(text, doc_id, title)\n",
    "            all_passages.extend(passages)\n",
    "        \n",
    "        passages_df = pd.DataFrame(all_passages)\n",
    "        \n",
    "        embeddings = self.generate_embeddings(all_passages)\n",
    "        \n",
    "        passages_df['passage_id'] = range(len(passages_df))\n",
    "        \n",
    "        print(f\"\\nСтатистика:\")\n",
    "        print(f\"Всего документов: {len(df)}\")\n",
    "        print(f\"Всего пассажей: {len(passages_df)}\")\n",
    "        print(f\"Среднее пассажей на документ: {len(passages_df) / len(df):.1f}\")\n",
    "        print(f\"Размер эмбеддингов: {embeddings.shape}\")\n",
    "        \n",
    "        return passages_df, embeddings\n",
    "    \n",
    "    def create_faiss_index(self, embeddings: np.ndarray) -> faiss.Index:\n",
    "        \"\"\"\n",
    "        Создает FAISS индекс для поиска\n",
    "        \"\"\"\n",
    "        dimension = embeddings.shape[1]\n",
    "        \n",
    "        index = faiss.IndexFlatIP(dimension)\n",
    "        \n",
    "        embeddings = embeddings.astype('float32')\n",
    "        \n",
    "        index.add(embeddings)\n",
    "        \n",
    "        print(f\"Создан FAISS индекс с {index.ntotal} векторами\")\n",
    "        return index\n",
    "    \n",
    "    def save_data(self, passages_df: pd.DataFrame, embeddings: np.ndarray, \n",
    "                 index: faiss.Index, output_dir: str = './vector_search_data'):\n",
    "        \"\"\"\n",
    "        Сохраняет все данные на диск\n",
    "        \"\"\"\n",
    "        import os\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        passages_df.to_parquet(f'{output_dir}/passages.parquet')\n",
    "        np.save(f'{output_dir}/embeddings.npy', embeddings)\n",
    "        faiss.write_index(index, f'{output_dir}/faiss_index.bin')\n",
    "        \n",
    "        config = {\n",
    "            'model_name': 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "            'passage_tokens': self.passage_tokens,\n",
    "            'overlap_tokens': self.overlap_tokens,\n",
    "            'max_tokens': self.max_tokens,\n",
    "            'total_passages': len(passages_df),\n",
    "            'embedding_dim': embeddings.shape[1]\n",
    "        }\n",
    "        \n",
    "        with open(f'{output_dir}/config.json', 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "        \n",
    "        print(f\"Данные сохранены в {output_dir}\")\n",
    "        \n",
    "        return output_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdb83f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train_documents)\n",
    "\n",
    "preprocessor = VectorSearchPreprocessor()\n",
    "\n",
    "passages_df, embeddings = preprocessor.process_dataframe(df)\n",
    "\n",
    "index = preprocessor.create_faiss_index(embeddings)\n",
    "\n",
    "output_dir = preprocessor.save_data(passages_df, embeddings, index)\n",
    "\n",
    "print(passages_df[['doc_id', 'passage_text', 'char_start', 'char_end']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fea5df1",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a285bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efda5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(f\"../datasets/vector_search_data/faiss_index.bin\")\n",
    "\n",
    "# Загружаем метаданные пассажей\n",
    "passages_df = pd.read_parquet(f\"../datasets/vector_search_data/passages.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a345549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode([\"test test test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c61d6f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[530727, 530721]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(embeddings, k=2)[1][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bdb7eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passage_tokens    [1997, 1006, 1037, 9415, 1007, 3231, 1006, 120...\n",
       "passage_text      of ( a substance ) test ( verb ) undergo a tes...\n",
       "char_start                                                     2293\n",
       "char_end                                                       2392\n",
       "doc_id                                                      D391809\n",
       "title                                     Definitions &Translations\n",
       "token_start                                                     507\n",
       "token_end                                                       539\n",
       "passage_id                                                   530721\n",
       "Name: 530721, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages_df.iloc[530721]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
